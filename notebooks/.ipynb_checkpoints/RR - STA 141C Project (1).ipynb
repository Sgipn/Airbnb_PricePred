{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb17001",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44434c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load Data\n",
    "listings = pd.read_csv(r\"/Users/mikaelalim/Downloads/Airbnb_PricePred-main/data/listings.csv\")\n",
    "listings.drop(\n",
    "    [\"Unnamed: 0\",], axis=1, inplace=True,\n",
    ")\n",
    "def standardizeData(data):\n",
    "    # Takes pandas dataframe and standardizes it iteratively\n",
    "    for column in data:\n",
    "        data[column] = (data[column] - np.mean(data[column])) / np.std(data[column])\n",
    "    return data\n",
    "listings = standardizeData(listings)\n",
    "\n",
    "# Define Price\n",
    "price = listings.loc[:,\"price\"]\n",
    "\n",
    "X = listings.drop([\"price\"], axis=1) #38837x232\n",
    "y = np.transpose(price) #1x38837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0eb7bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.02696316e-02 -4.62476119e-02  2.24361127e-03 -1.37860868e-02\n",
      "  1.15648112e-01 -2.05825880e-02 -2.40909547e-02  5.36196546e-02\n",
      " -3.19767178e-02 -1.41212179e-02 -3.05033525e-03 -3.31527930e-03\n",
      " -2.12060650e-03  2.78220850e-03  1.97339466e-03 -5.37588668e-03\n",
      "  2.53190590e-03 -7.73564374e-03  2.21965230e-04 -1.30147343e-03\n",
      " -2.70627324e-03  8.05702865e-03 -2.84620394e-03 -2.72026348e-02\n",
      "  1.34915853e-03 -1.50306826e-03 -2.09378294e-03 -9.89121895e-03\n",
      " -4.90817514e-03  4.89618359e-03 -1.20721800e-02  4.29613257e-03\n",
      " -2.40262192e-03 -8.82751047e-03 -5.11556454e-03  1.37968771e-02\n",
      " -6.59726798e-03 -6.61142268e-04 -2.44391269e-02 -1.02318620e-03\n",
      " -1.53834575e-02  1.02385357e-02 -2.90229224e-03  5.51913016e-04\n",
      "  3.09429402e-02 -2.75069403e-03 -2.80885774e-03  5.26667920e-04\n",
      " -3.33704429e-03 -2.02622109e-03 -3.99232004e-03  2.09707501e-02\n",
      " -1.20140549e-03  1.11577733e-02 -3.65998378e-03 -2.93198926e-03\n",
      " -5.39673551e-03 -5.40625932e-03 -3.64461243e-03 -6.72690993e-04\n",
      " -9.05626959e-03 -1.57890149e-02  9.34574172e-04  5.92972945e-03\n",
      " -8.67047329e-03 -3.08988800e-03 -3.16101542e-03  3.49542125e-03\n",
      " -3.66930346e-03 -6.34551154e-03 -1.23024555e-02 -1.33607421e-02\n",
      " -1.58602116e-03 -1.75257027e-02  8.32757643e-03 -2.27383195e-03\n",
      " -3.96376710e-03 -4.20019835e-03 -7.60553662e-03 -2.12391846e-03\n",
      " -2.37469085e-03 -4.64806459e-03 -2.44350534e-03  1.71876874e-02\n",
      " -1.56353986e-02  1.90386233e-02 -8.45746702e-03 -9.46874308e-03\n",
      " -4.35362117e-03 -1.85079211e-03  6.47422060e-03 -8.80314198e-03\n",
      " -2.95305982e-03 -6.55482539e-03  6.50873452e-03  1.13092035e-02\n",
      " -2.78903651e-03 -4.47916946e-03 -6.99664271e-03 -1.04887994e-03\n",
      "  1.00512952e-02  2.73213639e-02  8.75091147e-04 -3.73586737e-02\n",
      "  1.68793610e-02 -2.15272208e-03 -2.53052454e-03  2.72255594e-03\n",
      " -3.45270825e-03 -2.81622910e-03 -2.25028939e-03 -4.45656697e-03\n",
      " -2.42910799e-02 -9.30334447e-03 -1.01699882e-02 -1.78880886e-03\n",
      "  1.02841630e-03 -8.92583800e-03 -4.66986069e-03 -5.27130901e-03\n",
      " -4.28228909e-03  5.57454451e-04 -3.67180400e-03 -5.48089332e-04\n",
      "  2.01707574e-03 -1.01662626e-03  1.86737046e-03 -5.34986756e-03\n",
      "  9.67548778e-03 -3.99657347e-03 -4.78403754e-03 -2.25074844e-03\n",
      " -1.05262058e-02 -2.00874489e-03 -6.16543197e-03 -3.51675730e-03\n",
      "  6.58296923e-02 -1.07823011e-02 -1.63096743e-03 -1.35258301e-02\n",
      " -2.92552867e-03 -1.36445260e-03 -1.72493482e-03 -5.38206651e-03\n",
      " -1.27568147e-03 -4.69816715e-03  1.20241735e-02  1.76887844e-03\n",
      "  3.71651674e-03  1.11985911e-03 -1.66698708e-03 -1.96552297e-03\n",
      "  2.01114303e-02  2.54695529e-02 -2.17224816e-03 -3.43841802e-03\n",
      " -2.10141453e-03 -8.64859799e-04 -9.19697725e-03  1.09252315e-02\n",
      " -2.60397281e-03 -4.44626654e-03 -5.82587906e-03 -2.28743916e-03\n",
      " -1.47348822e-03 -3.94942202e-04  6.48042379e-03 -1.32076774e-02\n",
      " -1.10691713e-02 -6.06614615e-03 -8.84499154e-04 -7.39750810e-03\n",
      " -7.52777160e-03 -2.62723124e-03 -1.05096441e-02  6.99443255e-03\n",
      " -3.73538891e-03 -3.25067212e-03 -1.95220540e-03 -6.58892594e-03\n",
      " -1.88931097e-03 -1.89023552e-03  1.67244856e-02 -7.46618426e-03\n",
      " -2.62951894e-03 -1.13926407e-03  4.53975540e-02 -4.34740956e-03\n",
      "  3.19881882e-04 -5.15274028e-03  1.75272713e-03 -5.76541521e-03\n",
      " -3.54819305e-05 -6.45140542e-03 -3.24995981e-03 -3.13974947e-03\n",
      " -1.60694352e-03 -1.04575767e-02 -8.04896426e-03  2.18332400e-02\n",
      " -2.88599800e-03  1.89542603e-03 -5.25718648e-03 -9.22544201e-04\n",
      " -2.62540666e-03  7.36442475e-02 -4.03249013e-03 -3.23226711e-04\n",
      " -1.70728691e-03 -1.19506653e-02  1.66208182e-02 -2.11493500e-03\n",
      "  4.60759220e-03 -6.27213529e-03 -3.80707876e-02 -4.36033763e-03\n",
      " -6.72627826e-04  3.81746669e-02  1.05155453e-03 -1.48485333e-03\n",
      "  8.92097141e-04 -4.59276044e-03  2.29941129e-02  1.22675760e-03\n",
      " -4.58741454e-03 -9.20755029e-03 -2.70984752e-03 -4.97171053e-03\n",
      "  1.28383072e-01 -1.12483942e-01 -5.55525441e-02]\n",
      "The time it took to compute this is 0:00:00.153339 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Find Beta Values\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "start = timer()\n",
    "\n",
    "n,m = X.shape\n",
    "I = np.identity(m)\n",
    "alpha = 1\n",
    "b1norm = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X) + alpha * I), X.T), y)\n",
    "# print(b1norm)\n",
    "\n",
    "end = timer()\n",
    "print(\"The time it took to compute this is\", timedelta(seconds=end-start), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "380727c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean-squared error of the test data is 152.5034303188288\n",
      "The r-squared value of the test data is 0.20630124828463092\n"
     ]
    }
   ],
   "source": [
    "# Predict Accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# First, we split the data into an 80:20 train:test ratio\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Evaluation of Training Set\n",
    "rr = Ridge(alpha=0.01)\n",
    "rr.fit(x_train, y_train) \n",
    "pred_train_rr= rr.predict(x_train)\n",
    "RMSE_train = np.sqrt(mean_squared_error(y_train,pred_train_rr))\n",
    "RMSE_tr = r2_score(y_train, pred_train_rr)\n",
    "\n",
    "# Evaluation of Test Set\n",
    "pred_test_rr= rr.predict(x_test)\n",
    "RMSE_test = np.sqrt(mean_squared_error(y_test,pred_test_rr))\n",
    "r2_test = r2_score(y_test, pred_test_rr)\n",
    "\n",
    "print('The root mean-squared error of the test data is', RMSE_test)\n",
    "print('The r-squared value of the test data is', r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c74ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45e46a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values  17693   NaN\n",
      "9252    NaN\n",
      "37779   NaN\n",
      "dtype: float64\n",
      "Real values       17693   -0.331619\n",
      "9252    -0.224996\n",
      "37779   -0.417932\n",
      "Name: price, dtype: float64\n",
      "Trained W         nan\n",
      "Trained b         inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/99/_4z3fbb5325fb810kqmcqxnh0000gn/T/ipykernel_69673/1954947031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/99/_4z3fbb5325fb810kqmcqxnh0000gn/T/ipykernel_69673/1954947031.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Visualization on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'orange'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Salary vs Experience'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 3068\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4496\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# Ridge Regression\n",
    "  \n",
    "class RidgeRegression() :\n",
    "      \n",
    "    def __init__( self, learning_rate, iterations, l2_penality ) :\n",
    "          \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations        \n",
    "        self.l2_penality = l2_penality\n",
    "          \n",
    "    # Function for model training            \n",
    "    def fit( self, X, Y ) :\n",
    "          \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape\n",
    "          \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )\n",
    "          \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        Y_pred = self.predict( self.X )\n",
    "          \n",
    "        # calculate gradients      \n",
    "        dW = ( - ( 2 * ( self.X.T ).dot( self.Y - Y_pred ) ) +               \n",
    "               ( 2 * self.l2_penality * self.W ) ) / self.m     \n",
    "        db = - 2 * np.sum( self.Y - Y_pred ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db        \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "    def predict( self, X ) :    \n",
    "        return X.dot( self.W ) + self.b\n",
    "      \n",
    "# Driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset\n",
    "    df = pd.read_csv(r\"/Users/mikaelalim/Downloads/Airbnb_PricePred-main/data/listings.csv\")\n",
    "    df.drop([\"Unnamed: 0\",], axis=1, inplace=True,)\n",
    "    df.to_numpy()\n",
    "    \n",
    "    X = df.drop([\"price\"], axis=1) #38837x232\n",
    "    Y = np.transpose(price) #1x38837    \n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(X)\n",
    "    \n",
    "    def standardizeData(data):\n",
    "        for column in df:\n",
    "            if (df[column] != 0).sum() == 0:\n",
    "                continue\n",
    "            else:\n",
    "                df[column] = (df[column] - np.mean(df[column])) / np.std(df[column])\n",
    "        return df\n",
    "    \n",
    "    # Splitting dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \n",
    "                                            \n",
    "                                          test_size = 1 / 3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    model = RidgeRegression( iterations = 1000,                             \n",
    "                            learning_rate = 0.01, l2_penality = 1 )\n",
    "    model.fit( X_train, Y_train )\n",
    "      \n",
    "    # Prediction on test set\n",
    "    Y_pred = model.predict( X_test )    \n",
    "    print( \"Predicted values \", np.round( Y_pred[:3], 2 ) )     \n",
    "    print( \"Real values      \", Y_test[:3] )    \n",
    "    print( \"Trained W        \", round( model.W[0], 2 ) )    \n",
    "    print( \"Trained b        \", round( model.b, 2 ) )\n",
    "      \n",
    "    # Visualization on test set     \n",
    "    plt.scatter( X_test, Y_test, color = 'blue' )    \n",
    "    plt.plot( X_test, Y_pred, color = 'orange' )    \n",
    "    plt.title( 'Salary vs Experience' )    \n",
    "    plt.xlabel( 'Years of Experience' )    \n",
    "    plt.ylabel( 'Salary' )    \n",
    "    plt.show()\n",
    "      \n",
    "if __name__ == \"__main__\" : \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3806f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/99/_4z3fbb5325fb810kqmcqxnh0000gn/T/ipykernel_69673/1402415882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0my_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#Centering the y data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import linear_model\n",
    "\n",
    "def costFunctionReg(X,y,theta,lamda = 10):\n",
    "    '''Cost function for ridge regression (regularized L2)'''\n",
    "    #Initialization\n",
    "    m = len(y) \n",
    "    J = 0\n",
    "    \n",
    "    #Vectorized implementation\n",
    "    h = X @ theta\n",
    "    J_reg = (lamda / (2*m)) * np.sum(np.square(theta))\n",
    "    J = float((1./(2*m)) * (h - y).T @ (h - y)) + J_reg;\n",
    "    return(J)\n",
    "\n",
    "def gradient_descent_reg(X,y,theta,alpha = 0.0005,lamda = 10,num_iters=1000):\n",
    "    '''Gradient descent for ridge regression'''\n",
    "    #Initialisation of useful values \n",
    "    m = np.size(y)\n",
    "    J_history = np.zeros(num_iters)\n",
    "    theta_0_hist, theta_1_hist = [], [] #Used for three D plot\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        #Hypothesis function\n",
    "        h = np.dot(X,theta)\n",
    "        \n",
    "        #Grad function in vectorized form\n",
    "        theta = theta - alpha * (1/m)* (  (X.T @ (h-y)) + lamda * theta )\n",
    "           \n",
    "        #Cost function in vectorized form       \n",
    "        J_history[i] = costFunctionReg(X,y,theta,lamda)\n",
    "           \n",
    "        #Calculate the cost for each iteration(used to plot convergence)\n",
    "        theta_0_hist.append(theta[0,0])\n",
    "        theta_1_hist.append(theta[1,0])   \n",
    "    return theta ,J_history, theta_0_hist, theta_1_hist\n",
    "\n",
    "#Generating sine curve and uniform noise\n",
    "x = pd.read_csv(r\"/Users/mikaelalim/Downloads/Airbnb_PricePred-main/data/listings.csv\")\n",
    "x.drop([\"Unnamed: 0\",], axis=1, inplace=True,)\n",
    "x = listings.drop([\"price\"], axis=1) #38837x232\n",
    "x.to_numpy()\n",
    "noise = 1*np.random.uniform(size = 38837)\n",
    "\n",
    "y = listings.loc[:,\"price\"] \n",
    "y = np.transpose(price)\n",
    "y_noise = (y + noise).reshape(-1,1)\n",
    "\n",
    "#Centering the y data\n",
    "y_noise = y_noise - y_noise.mean()\n",
    "\n",
    "#Design matrix is x, x^2\n",
    "X = np.vstack((2*x,x**2)).T\n",
    "\n",
    "#Nornalizing the design matrix to facilitate visualization\n",
    "X = X / np.linalg.norm(X,axis = 0)\n",
    "\n",
    "#Plotting the result\n",
    "plt.scatter(x,y_noise, label = 'Dataset')\n",
    "plt.plot(x,y - y.mean(),label = 'Sine')\n",
    "plt.title('Noisy sine curve')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "l = 10\n",
    "\n",
    "#Setup of meshgrid of theta values\n",
    "T1, T2 = np.meshgrid(np.linspace(-10,10,100),np.linspace(-10,10,100))\n",
    "\n",
    "#Computing the cost function for each theta combination\n",
    "zs = np.array(  [costFunctionReg(X, y_noise.reshape(-1,1),np.array([t1,t2]).reshape(-1,1),l) \n",
    "                     for t1, t2 in zip(np.ravel(T1), np.ravel(T2)) ] )\n",
    "#Reshaping the cost values    \n",
    "Z = zs.reshape(T1.shape)\n",
    "\n",
    "\n",
    "#Computing the gradient descent\n",
    "theta_result_reg,J_history_reg, theta_0, theta_1 = gradient_descent_reg(X,y_noise,np.array([7.,10.]).reshape(-1,1), 0.8,l,num_iters=5000)\n",
    "\n",
    "\n",
    "#Angles needed for quiver plot\n",
    "anglesx = np.array(theta_0)[1:] - np.array(theta_0)[:-1]\n",
    "anglesy = np.array(theta_1)[1:] - np.array(theta_1)[:-1]\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (16,8))\n",
    "\n",
    "#Surface plot\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.plot_surface(T1, T2, Z, rstride = 5, cstride = 5, cmap = 'jet', alpha=0.5)\n",
    "ax.plot(theta_0,theta_1,J_history_reg, marker = '*', color = 'r', alpha = .4, label = 'Gradient descent')\n",
    "\n",
    "ax.set_xlabel('theta 1')\n",
    "ax.set_ylabel('theta 2')\n",
    "ax.set_zlabel('error')\n",
    "ax.set_title('RSS gradient descent: Root at {}'.format(theta_result_reg.ravel()))\n",
    "ax.view_init(45, -45)\n",
    "\n",
    "\n",
    "#Contour plot\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.contour(T1, T2, Z, 100, cmap = 'jet')\n",
    "ax.quiver(theta_0[:-1], theta_1[:-1], anglesx, anglesy, scale_units = 'xy', angles = 'xy', scale = 1, color = 'r', alpha = .9)\n",
    "ax.set_xlabel('theta 1')\n",
    "ax.set_ylabel('theta 2')\n",
    "\n",
    "plt.suptitle('Cost function and gradient descent: Ridge regularization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92c15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

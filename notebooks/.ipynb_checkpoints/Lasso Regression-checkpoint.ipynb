{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c4e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82297001",
   "metadata": {},
   "source": [
    "## Lasso Overview\n",
    "\n",
    "Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "Objective Function:\n",
    "\n",
    "$$ \\begin{eqnarray}\n",
    "\\underset{\\beta}{\\mathrm{argmin}} RSS_{lasso} (\\beta) &=& \\frac{1}{n} \\underset{\\beta}{\\mathrm{argmin}} (RSS_{OLS} (\\beta) + \\lambda |\\beta|_{1} )\\\\\n",
    "&=& \\underset{\\beta}{\\mathrm{argmin}} \\frac{1}{n} ||y - (\\beta)X)||^{2}_{2} + \\lambda |\\beta|_{1} \\\\ \n",
    "&=& f(\\beta) + g(\\beta)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "where $f(\\beta)$ is the $RSS_{OLS}$ term, and $g(\\beta)$ is the regularization factor for Lasso.\n",
    "\n",
    "After applying some subdifferentials and subderivatives, we find that the Objective function becomes: \n",
    "\n",
    "$$ \\begin{eqnarray}\n",
    "\\frac{\\partial d}{\\partial d \\beta_{j}} RSS_{Lasso} + \\partial \\beta_{j} \\lambda \\sum^{n}_{j=0} |\\beta_{j}|\n",
    "&=& - \\sum^{m}_{i=0} x_{j}^{i} (y^{i} - \\sum^{n}_{k \\ne j} \\theta_{k} x_{k}^{i} ) + \\theta_{j} \\sum^{m}_{i=1} (x_{j}^{i})^{2} + \\partial_{\\beta_{j}} \\lambda|\\beta_{j}| \\\\ \n",
    "&=& - \\rho_{j} +  \\beta_{j} z + \\partial_{\\beta_{j}} \\lambda|\\beta_{j}| \\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Proposed strategy:\n",
    "- Solve linear system via soft-thresholding with coordinate descent for given values of tuning parameter lambda.\n",
    "- Tuning lambda via 4-fold Cross validation. k value with lowest mean MSE will be chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e738fbc",
   "metadata": {},
   "source": [
    "### Lasso from scratch begins here: \n",
    "\n",
    "1. The setup: design matrix and response variable (price).\n",
    "2. Two functions: soft_thresholding and coordinate_descent_lasso are created. \n",
    "    - soft_thresholding: returns value of $\\beta^{(LASSO)}_{j}$  based on values of the OLS solution $\\hat{\\beta_{j}^{(OLS)}}$. The process involves finding the first derivative of the LASSO objective function- in whihc the OLS solution is factorized into the product of normalization constant $z_{j}$ and $\\rho$. The LASSO solution then becomes a piecewise solution based on the relative value of $\\rho$ and $\\lambda$: $\\rho > lambda$, $\\rho < -\\lambda$, $-\\lambda \\le \\rho \\le \\lambda$. soft_thresholding returns these piecewise solutions based on $\\rho$ and $\\lambda$ values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468754a6",
   "metadata": {},
   "source": [
    "### Importing data and defining functions (soft_threshold, coordinate_descent_lasso, lambda_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b1efb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "def soft_threshold(rho,lamda):\n",
    "    '''Soft threshold function used for normalized data and lasso regression'''\n",
    "    if rho < (-1 * lamda):\n",
    "        return (rho + lamda)\n",
    "    elif rho >  lamda:\n",
    "        return (rho - lamda)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38d699c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianni\\AppData\\Local\\Temp/ipykernel_29444/3907520898.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 32 is different from 232)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29444/3907520898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#Vectorized implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mX_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX_j\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 32 is different from 232)"
     ]
    }
   ],
   "source": [
    "# testing dont run\n",
    "\n",
    "m,n = X_train.shape\n",
    "norm = np.linalg.norm(X_train,axis = 0)\n",
    "for i in range(n):\n",
    "    if norm[i] != 0:\n",
    "        X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "\n",
    "#Looping until max number of iterations\n",
    "for i in range(100): \n",
    "\n",
    "    #Looping through each coordinate\n",
    "    for j in range(n):\n",
    "\n",
    "        #Vectorized implementation\n",
    "        X_j = X_train[:,j].reshape(-1,1)\n",
    "        y_pred = X_train @ theta\n",
    "        y_pred = y_pred.reshape(-1,1)\n",
    "        rho = X_j.T @ (y_train - y_pred  + theta[j]*X_j)\n",
    "        rho = float(rho)\n",
    "\n",
    "        #Checking intercept parameter\n",
    "\n",
    "        theta[j] =  soft_threshold(rho, 0.12)   \n",
    "\n",
    "temp = theta.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "def coordinate_descent_lasso(theta,X,y,lamda, num_iters=100, intercept = False):\n",
    "    '''Coordinate gradient descent for lasso regression - for normalized data. \n",
    "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
    "    \n",
    "    m,n = X_train.shape\n",
    "    norm = np.linalg.norm(X_train,axis = 0)\n",
    "    for i in range(n):\n",
    "        if norm[i] != 0:\n",
    "            X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "\n",
    "    #Looping until max number of iterations\n",
    "    for i in range(100): \n",
    "\n",
    "        #Looping through each coordinate\n",
    "        for j in range(n):\n",
    "\n",
    "            #Vectorized implementation\n",
    "            X_j = X_train[:,j].reshape(-1,1)\n",
    "            y_pred = X_train @ theta\n",
    "            y_pred = y_pred.reshape(-1,1)\n",
    "            rho = X_j.T @ (y_train - y_pred  + theta[j]*X_j)\n",
    "            rho = float(rho)\n",
    "\n",
    "            #Checking intercept parameter\n",
    "\n",
    "            theta[j] =  soft_threshold(rho, lamda) \n",
    "            \n",
    "    return theta.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "def lambda_tune(X_train,y_train):\n",
    "    \n",
    "    all_mse = list() # 300 total entries (lambda), each entry has 10 entries (10-fold)\n",
    "    lamda = np.logspace(0,7,300)/10 #Range of lambda values\n",
    "    \n",
    "    kf = KFold(n_splits = 10, random_state = True, shuffle = True)\n",
    "\n",
    "    for l in lamda:                                             # Iterate through all lambda (200)\n",
    "        mse_vals = list()\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):       # Iterate through each of 10 folds for each lamda \n",
    "            temp_X_train = X_train[train_index]\n",
    "            temp_y_train = y_train[train_index]\n",
    "            temp_X_test = X_train[test_index]\n",
    "            temp_y_test = y_train[test_index]\n",
    "            \n",
    "            n,p = temp_X_train.shape\n",
    "            initial_theta = np.ones((p,1))\n",
    "            MSE = 0\n",
    "\n",
    "            theta = coordinate_descent_lasso(initial_theta,temp_X_train,temp_y_train,lamda = l, num_iters=100) # fit lasso model\n",
    "            y_pred = temp_X_test @ theta                         # Predicted response values based on beta coefficients   \n",
    "            \n",
    "            for i in range(len(test_index)):\n",
    "                MSE += (temp_y_test[i][0] - y_pred[i])**2\n",
    "            MSE = MSE/n                                         # MSE of each of the 4 lasso models fitted to a given lambda \n",
    "            mse_vals.append(MSE)\n",
    "        all_mse.append(mse_vals)\n",
    "    return all_mse,lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "#Loading in Data\n",
    "df = pd.read_csv(\"../data/listings.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84461deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "Y = df[\"price\"]\n",
    "X = df.drop(\"price\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "X_train,y_train,X_test,y_test = X_train.to_numpy(),y_train.to_numpy(),X_test.to_numpy(),y_test.to_numpy()\n",
    "y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "def r2score(y_pred, y):\n",
    "    rss = np.sum((y_pred - y) ** 2)\n",
    "    tss = np.sum((y - y.mean()) ** 2)\n",
    "\n",
    "    r2 = 1 - (rss / tss)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if using all data\n",
    "# 32 variable data: \n",
    "X_df = df[\n",
    "    [\n",
    "        \"minimum_nights\",\n",
    "        \"number_of_reviews\",\n",
    "        \"reviews_per_month\",\n",
    "        \"calculated_host_listings_count\",\n",
    "        \"availability_365\",\n",
    "        \"neighbourhood_group_Bronx\",\n",
    "        \"neighbourhood_group_Brooklyn\",\n",
    "        \"neighbourhood_group_Manhattan\",\n",
    "        \"neighbourhood_group_Queens\",\n",
    "        \"neighbourhood_group_Staten Island\",\n",
    "        \"neighbourhood_Midtown\",\n",
    "        \"neighbourhood_Lower East Side\",\n",
    "        \"neighbourhood_Harlem\",\n",
    "        \"neighbourhood_Upper East Side\",\n",
    "        \"neighbourhood_Upper West Side\",\n",
    "        \"neighbourhood_Washington Heights\",\n",
    "        \"neighbourhood_East Harlem\",\n",
    "        \"neighbourhood_Chinatown\",\n",
    "        \"neighbourhood_East Village\",\n",
    "        \"neighbourhood_Financial District\",\n",
    "        \"neighbourhood_Morningside Heights\",\n",
    "        \"neighbourhood_Inwood\",\n",
    "        \"neighbourhood_Hell's Kitchen\",\n",
    "        \"neighbourhood_Battery Park City\",\n",
    "        \"neighbourhood_Chelsea\",\n",
    "        \"neighbourhood_Two Bridges\",\n",
    "        \"neighbourhood_Gramercy\",\n",
    "        \"neighbourhood_NoHo\",\n",
    "        \"neighbourhood_Greenwich Village\",\n",
    "        \"neighbourhood_SoHo\",\n",
    "        \"room_type_Entire home/apt\",\n",
    "        \"room_type_Private room\"\n",
    "    ]\n",
    "]\n",
    "X = X_df.to_numpy()\n",
    "y_df = df[[\"price\"]]\n",
    "y = y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 split for 32-var case\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21905ef",
   "metadata": {},
   "source": [
    "### Fitting Lasso: (No intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "# Initialize variables\n",
    "m,n = X_train.shape\n",
    "initial_theta = np.ones(n)\n",
    "theta_list = list()\n",
    "lamda = np.arange(0.1,10,0.1) #Range of lambda values\n",
    "\n",
    "#Run lasso regression for each lambda\n",
    "for l in lamda:\n",
    "    theta = coordinate_descent_lasso(initial_theta,X_train,y_train,lamda = l, num_iters=100)\n",
    "    theta_list.append(theta)\n",
    "\n",
    "# (theta,X,y,lamda = .01, num_iters=100, intercept = False)\n",
    "\n",
    "#Stack into numpy array\n",
    "theta_lasso = np.stack(theta_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \n",
    "\n",
    "# Visual on Lasso Path for Lambdas\n",
    "n,_ = theta_lasso.shape\n",
    "plt.figure(figsize = (12,8))\n",
    "cols = list(X_df.columns)\n",
    "\n",
    "for i in range(n):\n",
    "    plt.plot(lamda, theta_lasso[i], label = cols[i])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log($\\\\lambda$)')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso Paths')\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322ad66",
   "metadata": {},
   "source": [
    "### Tuning Lambda\n",
    "We conduct 10-fold cross validation:\n",
    "\n",
    "1. Split training set into 10 partitions. (for each iteration: 9 partitions are used for training, 1 for testing) \n",
    "2. 10 lasso models are trained for 300 lambda values.\n",
    "3. For each lambda value, find the mean MAE of the 10 lasso models. \n",
    "3. Select lambda = k that has lowest mean MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "all_mse, lamda = lambda_tune(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \n",
    "\n",
    "# Fitting Lasso on tuned lambda = 0.1241\n",
    "import timeit\n",
    "timestart = timeit.default_timer()           # start timer\n",
    "theta = coordinate_descent_lasso(initial_theta,X_train,y_train,lamda = 0.1241, num_iters=100)\n",
    "timeend = timeit.default_timer()             # end timer\n",
    "time_elapsed = (timeend - timestart) # calculate elapsed time\n",
    "\n",
    "time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a026e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "# Computing MSE of our fitted LASSO model\n",
    "y_pred = X_test@theta\n",
    "SSE = 0\n",
    "for i in range(7768):\n",
    "    SSE += (y_test[i][0] - y_pred[i])**2\n",
    "MSE = SSE/7768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0158686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \n",
    "\n",
    "# Visual of MSE against lamda\n",
    "\n",
    "n = 300\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(10):\n",
    "        plt.scatter(lamda[i], all_mse[i][j])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log($\\\\lambda$)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Cross Validated MAE from Lasso fit')\n",
    "plt.legend()\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204abe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "# Finding the minimum lamda value\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mse[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "lamda[min_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb070e",
   "metadata": {},
   "source": [
    "### Implementation using sklearn (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb613152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Fitting lasso model with lambda = 24244\n",
    "#clf = linear_model.Lasso(alpha=16, fit_intercept = False)\n",
    "#clf.fit(X_train,y_train)\n",
    "#clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "m,n = X_train.shape\n",
    "theta_list_sk = list()\n",
    "lamda = np.arange(0.01,5,0.01) #Range of lambda values\n",
    "\n",
    "#Run lasso regression for each lambda\n",
    "for l in lamda:\n",
    "    clf = linear_model.Lasso(alpha = l, fit_intercept = False)\n",
    "    clf.fit(X_train,y_train)\n",
    "    theta_list_sk.append(clf.coef_)\n",
    "\n",
    "#Stack into numpy array\n",
    "theta_lasso_sk = np.stack(theta_list_sk).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SK_Lasso Path\n",
    "\n",
    "#Plot results\n",
    "n,_ = theta_lasso_sk.shape\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "for i in range(n):\n",
    "    plt.plot(lamda, theta_lasso_sk[i], label = cols[i])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log($\\\\lambda$)')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso Paths')\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44748d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import column_or_1d\n",
    "y_train = column_or_1d(y_train, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce743ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=4, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "model = LassoCV(alphas=np.logspace(0,4,300)/10, cv=cv, n_jobs=-1)\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "# summarize chosen configuration\n",
    "print('alpha: %f' % model.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f82ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_tune_SK(X_train,y_train,k):\n",
    "    \n",
    "    all_mae = list() # 300 total entries (lambda), each entry has k entries (k-fold)\n",
    "    all_mse = list() # 300 total entries (lambda), each entry has k entries (k-fold)\n",
    "    lamda = np.logspace(0,7,300)/10 #Range of lambda values\n",
    "    \n",
    "    kf = KFold(n_splits = k)\n",
    "\n",
    "    for l in lamda:                                             # Iterate through all lambda (200)\n",
    "        mae_vals = list()                                       # list of MAE values for each lambda. Resets for each lambda\n",
    "        mse_vals = list()\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):       # Iterate through each of 10 folds for each lamda \n",
    "            temp_X_train = X_train[train_index]\n",
    "            temp_y_train = y_train[train_index]\n",
    "            temp_X_test = X_train[test_index]\n",
    "            temp_y_test = y_train[test_index]\n",
    "            \n",
    "            MAE = 0\n",
    "            MSE = 0\n",
    "            \n",
    "            clf = linear_model.Lasso(alpha= l , fit_intercept = False)\n",
    "            clf.fit(temp_X_train,temp_y_train)\n",
    "            \n",
    "            y_pred = temp_X_test @ clf.coef_                     # Predicted response values based on beta coefficients                \n",
    "            for i in range(len(test_index)):\n",
    "                MAE += abs(temp_y_test[i][0] - y_pred[i])\n",
    "                MSE += (temp_y_test[i][0] - y_pred[i])**2\n",
    "            MAE = MAE/len(test_index)                           # MAE of each lasso model (10) for each lambda (300)\n",
    "            MSE = MSE/len(test_index)                                         # MSE of each lasso model (10) for each lambda (300) \n",
    "            mae_vals.append(MAE)\n",
    "            mse_vals.append(MSE)\n",
    "        all_mae.append(mae_vals)                                # Appending 10 MAE values from 10 fitted lasso models\n",
    "        all_mse.append(mse_vals)\n",
    "    return all_mae, all_mse,lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "\n",
    "all_mae_sk, all_mse_sk, lamda = lambda_tune_SK(X_train,y_train,3)\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mae_sk[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "\n",
    "lamda[min_index] # 0.13818733056536323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c1031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-fold cross validation\n",
    "\n",
    "all_mae_sk, all_mse_sk, lamda = lambda_tune_SK(X_train,y_train,4)\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mae_sk[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "lamda[min_index] # 0.1240639159058832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "all_mae_sk, all_mse_sk, lamda = lambda_tune_SK(X_train,y_train,5)\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mae_sk[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "lamda[min_index] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-fold cross validation\n",
    "\n",
    "all_mae_sk, all_mse_sk, lamda = lambda_tune_SK(X_train,y_train,6)\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mae_sk[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "lamda[min_index] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE against lamda (sk-lasso model)\n",
    "\n",
    "n = 300\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "for i in range(140):\n",
    "    for j in range(10):\n",
    "        plt.scatter(lamda[i], all_mse_sk[i][j])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log($\\\\lambda$)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Cross Validated MSE from Lasso fit')\n",
    "plt.legend()\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the minimum lamda value\n",
    "allmeans = list()\n",
    "for i in range(300):\n",
    "    allmeans.append(np.mean(all_mse_sk[i]))\n",
    "\n",
    "min_index = allmeans.index(min(allmeans))\n",
    "lamda[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a981a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [FROM SCRATCH] Tuned hyperparameter model:\n",
    "\n",
    "# Initialize variables\n",
    "m,n = X_train.shape\n",
    "initial_theta = np.ones((n,1))\n",
    "\n",
    "#Run lasso regression for tuned lambda\n",
    "theta = coordinate_descent_lasso(initial_theta,X_train,y_train,lamda = 24244, num_iters=300)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a7b52",
   "metadata": {},
   "source": [
    "## Generating final model \n",
    "- Recap: \n",
    "    - Hyperparameter tuning: \n",
    "        - Coordinate_descent: lambda = 24244 (minimum MSE & minimum MAE) \n",
    "        - Sk_lasso: lambda = 16.75252472408214 (MAE), lambda = 0.1 (MSE)\n",
    "    - Lasso model without intercept is chosen because of strange lasso path that has increasing beta value.\n",
    "    \n",
    " - SK_Lasso Model: 5 variables: \n",
    "     - availability_365, 'neighbourhood_group_Brooklyn', 'neighbourhood_group_Manhattan', 'room_type_Entire home/apt', 'room_type_Private room'.\n",
    "     - $$y = 17.21323117 X_{availability365} + 2.6954145 X_{neighbourhoodgroup(Brooklyn)} + 27.00013305 X_{neighbourhoodgroup(Manhattan)} + 68.55946047 X_{roomtype(home/apt)} + 14.12280336 X_{roomtype(Private room)} + \\epsilon$$ with $\\epsilon$: noise term, and $\\lambda = 16.75252472408214$ tuned from minimium MAE\n",
    " - Coordinate_descent Model: 1 variable: \n",
    "     - $y = 909.26194755 X_{room_type_Private room} + \\epsilon$ with $\\lambda = 24244$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "SSE = 0\n",
    "MSE = 0\n",
    "reg = LassoCV(cv=4, random_state=0).fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "for i in range(len(y_test)):\n",
    "    SSE += (y_test[i][0] - y_pred[i])**2\n",
    "MSE = SSE/len(y_test)\n",
    "MSE\n",
    "#print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bc507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha= 0.1240639159058832 , fit_intercept = False)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.coef_\n",
    "#clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd112518",
   "metadata": {},
   "source": [
    "$y = -0.182464069 X_{minimum-nights} -1.82117495e-01 X_{number-of-reviews} -0.695580768 X_{reviews-per-month} -0.118862286 X_{calculated-host-listings-count} + 0.168603554 X_{availability-365} + 31.9489793 X_{neighbourhood-group-Manhattan} + 103.751173 X_{neighbourhood-group-Queens} + 11.9852278 X_{neighbourhood-Midtown} + 40.2303655 X_{neighbourhood-Harlem} -9.67773714 X_{neighbourhood-Upper-East-Side} -62.6200141 X_{neighbourhood-Upper-West-Side} -47.6993652 X_{neighbourhood-Washington Heights} -12.8789731 X_{neighbourhood-East-Harlem} -81.3895706 X_{neighbourhood-Chinatown} -41.7801134 X_{neighbourhood-East-Village} -26.5955374 X_{neighbourhood-Morningside-Heights} -26.2925742 X_{neighbourhood-Inwood} -50.3509698 X_{neighbourhood_Hell's Kitchen} -76.9919226 X_{neighbourhood-Chelsea} + 15.1316531 X_{neighbourhood-Greenwich-Village} + 64.6189443 X_{neighbourhood-SoHo} + 129.609606 X_{room-type(Entire home/apt)} + 29.3556169 X_{room-type-Private room} + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85762df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [0,1,2,3,4,6,7,8,10,11,12,13,14,15,16,17,18,20,21,22,24,28,29,30,31]\n",
    "for i in num:\n",
    "    print(cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb12df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_adj = ((1 - 0.11835175406167764) * (31069 + 7768)) / (31069 + 7768 - 25 - 1)\n",
    "r_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df457101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols[4] # availability_365\n",
    "#cols[6] # 'neighbourhood_group_Brooklyn'\n",
    "#cols[7] # 'neighbourhood_group_Manhattan'\n",
    "#cols[30] # 'room_type_Entire home/apt'\n",
    "#cols[31] # 'room_type_Private room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MSE of model against testing data:\n",
    "import timeit\n",
    "timestart = timeit.default_timer()           # start timer\n",
    "clf = linear_model.Lasso(alpha= 16.75252472408214 , fit_intercept = False)\n",
    "clf.fit(X_train,y_train)\n",
    "timeend = timeit.default_timer()             # end timer\n",
    "time_elapsed = (timeend - timestart) # calculate elapsed time\n",
    "\n",
    "y_pred = X_test@clf.coef_\n",
    "y_pred\n",
    "MSE = 0\n",
    "MAE = 0\n",
    "n = len(y_test)\n",
    "for i in range(n):\n",
    "    MSE += (y_test[i][0] - y_pred[i])**2\n",
    "    MAE += abs(y_test[i][0] - y_pred[i])\n",
    "MSE = MSE/n\n",
    "MAE = MAE/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The MSE of our Lasso model is: \",MSE)\n",
    "print(\"The MAE of our Lasso model is: \",MAE)\n",
    "print(\"The training run-time for our Lasso model is: \",time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86011b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    " \n",
    "corr_matrix = numpy.corrcoef(y_test[:,0], y_pred)\n",
    "corr = corr_matrix[0,1]\n",
    "R_sq = corr**2\n",
    " \n",
    "print(R_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38f6ca",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "- Sparse solution is created-- that is robust against multicollinearity. Dimension is reduced from 32 variables to 5 of the most important ones. \n",
    "- MSE = 8517915.669298718\n",
    "- MAE = 1933.9078181510783\n",
    "- Run time: 0.04226710001239553 seconds\n",
    "- R^2: 0.008392621529298826"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffadb84",
   "metadata": {},
   "source": [
    "## Testing with Iris Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
    ")\n",
    "iris = iris.drop(\"species\", axis=1)\n",
    "display(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeData(data):\n",
    "    # Takes pandas dataframe and standardizes it iteratively\n",
    "    for column in data:\n",
    "        if (data[column] != 0).sum() == 0:  # If the column is all zeros\n",
    "            continue  # No need to standardize all zeros (thus dividing by zero)\n",
    "        else:\n",
    "            data[column] = (data[column] - np.mean(data[column])) / np.std(data[column])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_iris, Xtest_iris, Ytrain_iris, Ytest_iris = train_test_split(\n",
    "    iris.drop(\"sepal_length\", axis=1),\n",
    "    iris[\"sepal_length\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Standardize our X matrices\n",
    "Xtrain_iris, Xtest_iris = standardizeData(Xtrain_iris), standardizeData(Xtest_iris)\n",
    "\n",
    "# Do the model\n",
    "model = linear_model.Lasso(alpha= 16.75252472408214 , fit_intercept = False)\n",
    "model.fit(Xtrain_iris,Ytrain_iris)\n",
    "\n",
    "Y_pred_iris = model.predict(Xtest_iris)\n",
    "display(pd.DataFrame({\"Predictions\": Y_pred_iris, \"Actual\": Ytest_iris}).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
